{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af7941d4-0975-44f5-96fe-0dca513c5372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import altair as alt\n",
    "## Sklearn package\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.preprocessing import RobustScaler, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from scipy.stats import skew, kurtosis\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_colwidth = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8e1129b1-e794-4537-9e50-b11048fc16c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>event_id</th><th>down_time</th><th>up_time</th><th>action_time</th><th>activity</th><th>down_event</th><th>up_event</th><th>text_change</th><th>cursor_position</th><th>word_count</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;001519c8&quot;</td><td>1</td><td>4526</td><td>4557</td><td>31</td><td>&quot;Nonproduction&quot;</td><td>&quot;Leftclick&quot;</td><td>&quot;Leftclick&quot;</td><td>&quot;NoChange&quot;</td><td>0</td><td>0</td></tr><tr><td>&quot;001519c8&quot;</td><td>2</td><td>4558</td><td>4962</td><td>404</td><td>&quot;Nonproduction&quot;</td><td>&quot;Leftclick&quot;</td><td>&quot;Leftclick&quot;</td><td>&quot;NoChange&quot;</td><td>0</td><td>0</td></tr><tr><td>&quot;001519c8&quot;</td><td>3</td><td>106571</td><td>106571</td><td>0</td><td>&quot;Nonproduction&quot;</td><td>&quot;Shift&quot;</td><td>&quot;Shift&quot;</td><td>&quot;NoChange&quot;</td><td>0</td><td>0</td></tr><tr><td>&quot;001519c8&quot;</td><td>4</td><td>106686</td><td>106777</td><td>91</td><td>&quot;Input&quot;</td><td>&quot;q&quot;</td><td>&quot;q&quot;</td><td>&quot;q&quot;</td><td>1</td><td>1</td></tr><tr><td>&quot;001519c8&quot;</td><td>5</td><td>107196</td><td>107323</td><td>127</td><td>&quot;Input&quot;</td><td>&quot;q&quot;</td><td>&quot;q&quot;</td><td>&quot;q&quot;</td><td>2</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 11)\n",
       "┌──────────┬──────────┬───────────┬─────────┬───┬───────────┬────────────┬────────────┬────────────┐\n",
       "│ id       ┆ event_id ┆ down_time ┆ up_time ┆ … ┆ up_event  ┆ text_chang ┆ cursor_pos ┆ word_count │\n",
       "│ ---      ┆ ---      ┆ ---       ┆ ---     ┆   ┆ ---       ┆ e          ┆ ition      ┆ ---        │\n",
       "│ str      ┆ i64      ┆ i64       ┆ i64     ┆   ┆ str       ┆ ---        ┆ ---        ┆ i64        │\n",
       "│          ┆          ┆           ┆         ┆   ┆           ┆ str        ┆ i64        ┆            │\n",
       "╞══════════╪══════════╪═══════════╪═════════╪═══╪═══════════╪════════════╪════════════╪════════════╡\n",
       "│ 001519c8 ┆ 1        ┆ 4526      ┆ 4557    ┆ … ┆ Leftclick ┆ NoChange   ┆ 0          ┆ 0          │\n",
       "│ 001519c8 ┆ 2        ┆ 4558      ┆ 4962    ┆ … ┆ Leftclick ┆ NoChange   ┆ 0          ┆ 0          │\n",
       "│ 001519c8 ┆ 3        ┆ 106571    ┆ 106571  ┆ … ┆ Shift     ┆ NoChange   ┆ 0          ┆ 0          │\n",
       "│ 001519c8 ┆ 4        ┆ 106686    ┆ 106777  ┆ … ┆ q         ┆ q          ┆ 1          ┆ 1          │\n",
       "│ 001519c8 ┆ 5        ┆ 107196    ┆ 107323  ┆ … ┆ q         ┆ q          ┆ 2          ┆ 1          │\n",
       "└──────────┴──────────┴───────────┴─────────┴───┴───────────┴────────────┴────────────┴────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_logs = pl.scan_csv(\"data/raw/train_logs.csv\")\n",
    "display(train_logs.collect().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2794aa4-8948-49a9-b407-fa37b94c9ae4",
   "metadata": {},
   "source": [
    "## Generate Features from train logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0b3ab7d6-3a16-4e9d-b388-09e7f08d4842",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor():\n",
    "    def __init__(self, logs):\n",
    "        self.logs = logs # Training logs\n",
    "        \n",
    "    def count_by_values(self, colname, used_cols):\n",
    "        fts = self.logs.select(pl.col('id').unique(maintain_order=True))\n",
    "        for i, col in enumerate(used_cols):\n",
    "            tmp_logs = self.logs.group_by('id').agg(\n",
    "                            pl.col(colname).is_in([col]).sum().alias(f'{colname}_{i}_cnt')\n",
    "                                    )\n",
    "            fts  = fts.join(tmp_logs, on='id', how='left') \n",
    "        return fts\n",
    "    \n",
    "    def create_count_by_values_feats(self):\n",
    "        activities = ['Input', 'Remove/Cut', 'Nonproduction', 'Replace', 'Paste']\n",
    "        events = ['q', 'Space', 'Backspace', 'Shift', 'ArrowRight', 'Leftclick', 'ArrowLeft', '.',\n",
    "                       ',', 'ArrowDown', 'ArrowUp', 'Enter', 'CapsLock', \"'\", 'Delete', 'Unidentified']\n",
    "        text_changes = ['q', ' ', '.', ',', '\\n', \"'\", '\"', '-', '?', ';', '=', '/', '\\\\', ':']        \n",
    "        #=== Create the feature columns using count by values ===\n",
    "        df = self.count_by_values('activity', activities) # Create 'activity' column\n",
    "        df = df.join(self.count_by_values('text_change', text_changes), on='id', how='left') \n",
    "        df = df.join(self.count_by_values('down_event', events), on='id', how='left') \n",
    "        df = df.join(self.count_by_values('up_event', events), on='id', how='left')\n",
    "        # print(df.collect().head())\n",
    "        return df\n",
    "\n",
    "    # Create the features \n",
    "    def create_input_words_feats(self):\n",
    "        # Filter no changes \n",
    "        df = self.logs.filter((~pl.col('text_change').str.contains('=>')) & (pl.col('text_change') != 'NoChange'))\n",
    "        # Aggregate the text changes by id\n",
    "        df = df.group_by('id').agg(pl.col('text_change').str.concat('').str.extract_all(r'q+'))\n",
    "        # creates only two columns ('id' and 'text_change') \n",
    "        df = df.with_columns(input_word_count=pl.col('text_change').list.lengths(),\n",
    "                             input_word_length_mean=pl.col('text_change').apply(lambda x: np.mean([len(i) for i in x] if len(x) > 0 else 0)),\n",
    "                             input_word_length_max=pl.col('text_change').apply(lambda x: np.max([len(i) for i in x] if len(x) > 0 else 0)),\n",
    "                             input_word_length_std=pl.col('text_change').apply(lambda x: np.std([len(i) for i in x] if len(x) > 0 else 0)),\n",
    "                             input_word_length_median=pl.col('text_change').apply(lambda x: np.median([len(i) for i in x] if len(x) > 0 else 0)),\n",
    "                             input_word_length_skew=pl.col('text_change').apply(lambda x: skew([len(i) for i in x] if len(x) > 0 else 0)))\n",
    "        df = df.drop('text_change') # Remove 'text_change' to avoid including duplicated `text_change` column\n",
    "        return df\n",
    "    \n",
    "    # Create the statistical numeric features (e.g. sum, median, mean min, 0.5_quantile)\n",
    "    def create_numeric_feats(self):\n",
    "        num_cols = ['down_time', 'up_time', 'action_time', 'cursor_position', 'word_count']\n",
    "        df = self.logs.group_by(\"id\").agg(pl.sum('action_time').suffix('_sum'),\n",
    "                                                pl.mean(num_cols).suffix('_mean'),\n",
    "                                                pl.std(num_cols).suffix('_std'),\n",
    "                                                pl.median(num_cols).suffix('_median'), pl.min(num_cols).suffix('_min'), pl.max(num_cols).suffix('_max'),\n",
    "                                                pl.quantile(num_cols, 0.5).suffix('_quantile'))\n",
    "        return df\n",
    "    \n",
    "    def create_categorical_feats(self):\n",
    "        df  = self.logs.group_by(\"id\").agg(\n",
    "                pl.n_unique(['activity', 'down_event', 'up_event', 'text_change']))\n",
    "        return df\n",
    "    \n",
    "    # Create the idle time features \n",
    "    def create_idle_time_feats(self):\n",
    "        df = self.logs.with_columns(pl.col('up_time').shift().over('id').alias('up_time_lagged'))\n",
    "        df = df.with_columns((abs(pl.col('down_time') - pl.col('up_time_lagged')) / 1000).fill_null(0).alias('time_diff'))\n",
    "        df = df.filter(pl.col('activity').is_in(['Input', 'Remove/Cut']))\n",
    "        df = df.group_by(\"id\").agg(inter_key_largest_lantency = pl.max('time_diff'),\n",
    "                                   inter_key_median_lantency = pl.median('time_diff'),\n",
    "                                   mean_pause_time = pl.mean('time_diff'),\n",
    "                                   std_pause_time = pl.std('time_diff'),\n",
    "                                   total_pause_time = pl.sum('time_diff'),\n",
    "                                   pauses_half_sec = pl.col('time_diff').filter((pl.col('time_diff') > 0.5) & (pl.col('time_diff') < 1)).count(),\n",
    "                                   pauses_1_sec = pl.col('time_diff').filter((pl.col('time_diff') > 1) & (pl.col('time_diff') < 1.5)).count(),\n",
    "                                   pauses_1_half_sec = pl.col('time_diff').filter((pl.col('time_diff') > 1.5) & (pl.col('time_diff') < 2)).count(),\n",
    "                                   pauses_2_sec = pl.col('time_diff').filter((pl.col('time_diff') > 2) & (pl.col('time_diff') < 3)).count(),\n",
    "                                   pauses_3_sec = pl.col('time_diff').filter(pl.col('time_diff') > 3).count(),)\n",
    "        return df\n",
    "    \n",
    "    # Create p-bursts features using up and down time and activity\n",
    "    def create_p_bursts_feats(self):\n",
    "        df = self.logs.with_columns(pl.col('up_time').shift().over('id').alias('up_time_lagged'))\n",
    "        df = df.with_columns((abs(pl.col('down_time') - pl.col('up_time_lagged')) / 1000).fill_null(0).alias('time_diff'))\n",
    "        df = df.filter(pl.col('activity').is_in(['Input', 'Remove/Cut']))\n",
    "        df = df.with_columns(pl.col('time_diff')<2)\n",
    "        df = df.with_columns(pl.when(pl.col(\"time_diff\") & pl.col(\"time_diff\").is_last()).then(pl.count()).over(pl.col(\"time_diff\").rle_id()).alias('P-bursts'))\n",
    "        df = df.drop_nulls()\n",
    "        df = df.group_by(\"id\").agg(pl.mean('P-bursts').suffix('_mean'),\n",
    "                                   pl.std('P-bursts').suffix('_std'),\n",
    "                                   pl.count('P-bursts').suffix('_count'),\n",
    "                                   pl.median('P-bursts').suffix('_median'),\n",
    "                                   pl.max('P-bursts').suffix('_max'),\n",
    "                                   pl.first('P-bursts').suffix('_first'),\n",
    "                                   pl.last('P-bursts').suffix('_last'))\n",
    "        return df\n",
    "    \n",
    "    # Create r-burst features using activity \n",
    "    def create_r_bursts_feats(self):\n",
    "        df = self.logs.filter(pl.col('activity').is_in(['Input', 'Remove/Cut']))\n",
    "        df = df.with_columns(pl.col('activity').is_in(['Remove/Cut']))\n",
    "        df = df.with_columns(pl.when(pl.col(\"activity\") & pl.col(\"activity\").is_last()).then(pl.count()).over(pl.col(\"activity\").rle_id()).alias('R-bursts'))\n",
    "        df = df.drop_nulls()\n",
    "        df = df.group_by(\"id\").agg(pl.mean('R-bursts').suffix('_mean'),\n",
    "                                   pl.std('R-bursts').suffix('_std'), \n",
    "                                   pl.median('R-bursts').suffix('_median'),\n",
    "                                   pl.max('R-bursts').suffix('_max'),\n",
    "                                   pl.first('R-bursts').suffix('_first'),\n",
    "                                   pl.last('R-bursts').suffix('_last'))\n",
    "        return df\n",
    "    \n",
    "    # Main function creates all 122 features\n",
    "    def create_feats(self):\n",
    "        feats = self.create_count_by_values_feats()  # 52 columns in total\n",
    "#         print(f\"< Count by values features > {len(feats.columns)}\")        \n",
    "        feats = feats.join(self.create_input_words_feats(), on='id', how='left')  # 58 columns\n",
    "#         print(f\"< Input words stats features > {len(feats.columns)}\")\n",
    "        feats = feats.join(self.create_numeric_feats(), on='id', how='left') # 89 columns\n",
    "#         print(f\"< Numerical features > {len(feats.columns)}\")\n",
    "        feats = feats.join(self.create_categorical_feats(), on='id', how='left') # 93 columns      \n",
    "#         print(f\"< Categorical features > {len(feats.columns)}\")\n",
    "        feats = feats.join(self.create_idle_time_feats(), on='id', how='left') # 103 columns\n",
    "#         print(f\"< Idle time features > {len(feats.columns)}\")\n",
    "        feats = feats.join(self.create_p_bursts_feats(), on='id', how='left') # 110 columns\n",
    "#         print(f\"< P-bursts features > {len(feats.columns)}\")\n",
    "        feats = feats.join(self.create_r_bursts_feats() , on='id', how='left') # 116 columns\n",
    "#         print(f\"< R-bursts features > {len(feats.columns)}\")        \n",
    "        return feats # 116 features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "545f75b8-53ed-4ebb-85de-aed3c0f4caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = FeatureExtractor(train_logs)\n",
    "train_feats = fe.create_feats() # Extract features from trainning logs (polars df)\n",
    "train_feats = train_feats.collect().to_pandas() # Convert polars df to pandas df\n",
    "train_feats.to_csv(\"train_feats_0.csv\")\n",
    "# print(train_feats.describe())\n",
    "train_logs = train_logs.collect().to_pandas()  # Convert polars df to pandas df\n",
    "del fe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:573]",
   "language": "python",
   "name": "conda-env-573-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
