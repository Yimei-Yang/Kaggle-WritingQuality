{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af7941d4-0975-44f5-96fe-0dca513c5372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, random, pickle, gc, os\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import altair as alt\n",
    "## Sklearn package\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.preprocessing import RobustScaler, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from scipy.stats import skew, kurtosis\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_colwidth = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e1129b1-e794-4537-9e50-b11048fc16c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>event_id</th><th>down_time</th><th>up_time</th><th>action_time</th><th>activity</th><th>down_event</th><th>up_event</th><th>text_change</th><th>cursor_position</th><th>word_count</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;001519c8&quot;</td><td>1</td><td>4526</td><td>4557</td><td>31</td><td>&quot;Nonproduction&quot;</td><td>&quot;Leftclick&quot;</td><td>&quot;Leftclick&quot;</td><td>&quot;NoChange&quot;</td><td>0</td><td>0</td></tr><tr><td>&quot;001519c8&quot;</td><td>2</td><td>4558</td><td>4962</td><td>404</td><td>&quot;Nonproduction&quot;</td><td>&quot;Leftclick&quot;</td><td>&quot;Leftclick&quot;</td><td>&quot;NoChange&quot;</td><td>0</td><td>0</td></tr><tr><td>&quot;001519c8&quot;</td><td>3</td><td>106571</td><td>106571</td><td>0</td><td>&quot;Nonproduction&quot;</td><td>&quot;Shift&quot;</td><td>&quot;Shift&quot;</td><td>&quot;NoChange&quot;</td><td>0</td><td>0</td></tr><tr><td>&quot;001519c8&quot;</td><td>4</td><td>106686</td><td>106777</td><td>91</td><td>&quot;Input&quot;</td><td>&quot;q&quot;</td><td>&quot;q&quot;</td><td>&quot;q&quot;</td><td>1</td><td>1</td></tr><tr><td>&quot;001519c8&quot;</td><td>5</td><td>107196</td><td>107323</td><td>127</td><td>&quot;Input&quot;</td><td>&quot;q&quot;</td><td>&quot;q&quot;</td><td>&quot;q&quot;</td><td>2</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 11)\n",
       "┌──────────┬──────────┬───────────┬─────────┬───┬───────────┬────────────┬────────────┬────────────┐\n",
       "│ id       ┆ event_id ┆ down_time ┆ up_time ┆ … ┆ up_event  ┆ text_chang ┆ cursor_pos ┆ word_count │\n",
       "│ ---      ┆ ---      ┆ ---       ┆ ---     ┆   ┆ ---       ┆ e          ┆ ition      ┆ ---        │\n",
       "│ str      ┆ i64      ┆ i64       ┆ i64     ┆   ┆ str       ┆ ---        ┆ ---        ┆ i64        │\n",
       "│          ┆          ┆           ┆         ┆   ┆           ┆ str        ┆ i64        ┆            │\n",
       "╞══════════╪══════════╪═══════════╪═════════╪═══╪═══════════╪════════════╪════════════╪════════════╡\n",
       "│ 001519c8 ┆ 1        ┆ 4526      ┆ 4557    ┆ … ┆ Leftclick ┆ NoChange   ┆ 0          ┆ 0          │\n",
       "│ 001519c8 ┆ 2        ┆ 4558      ┆ 4962    ┆ … ┆ Leftclick ┆ NoChange   ┆ 0          ┆ 0          │\n",
       "│ 001519c8 ┆ 3        ┆ 106571    ┆ 106571  ┆ … ┆ Shift     ┆ NoChange   ┆ 0          ┆ 0          │\n",
       "│ 001519c8 ┆ 4        ┆ 106686    ┆ 106777  ┆ … ┆ q         ┆ q          ┆ 1          ┆ 1          │\n",
       "│ 001519c8 ┆ 5        ┆ 107196    ┆ 107323  ┆ … ┆ q         ┆ q          ┆ 2          ┆ 1          │\n",
       "└──────────┴──────────┴───────────┴─────────┴───┴───────────┴────────────┴────────────┴────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_logs = pl.scan_csv(\"data/raw/train_logs.csv\")\n",
    "display(train_logs.collect().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2794aa4-8948-49a9-b407-fa37b94c9ae4",
   "metadata": {},
   "source": [
    "## Generate Features from train logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b3ab7d6-3a16-4e9d-b388-09e7f08d4842",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor():\n",
    "    def __init__(self, logs):\n",
    "        self.logs = logs # Training logs\n",
    "        \n",
    "    def count_by_values(self, colname, used_cols):\n",
    "        fts = self.logs.select(pl.col('id').unique(maintain_order=True))\n",
    "        for i, col in enumerate(used_cols):\n",
    "            tmp_logs = self.logs.group_by('id').agg(\n",
    "                            pl.col(colname).is_in([col]).sum().alias(f'{colname}_{i}_cnt')\n",
    "                                    )\n",
    "            fts  = fts.join(tmp_logs, on='id', how='left') \n",
    "        return fts\n",
    "    \n",
    "    def create_count_by_values_feats(self):\n",
    "        activities = ['Input', 'Remove/Cut', 'Nonproduction', 'Replace', 'Paste']\n",
    "        events = ['q', 'Space', 'Backspace', 'Shift', 'ArrowRight', 'Leftclick', 'ArrowLeft', '.',\n",
    "                       ',', 'ArrowDown', 'ArrowUp', 'Enter', 'CapsLock', \"'\", 'Delete', 'Unidentified']\n",
    "        text_changes = ['q', ' ', '.', ',', '\\n', \"'\", '\"', '-', '?', ';', '=', '/', '\\\\', ':']        \n",
    "        #=== Create the feature columns using count by values ===\n",
    "        df = self.count_by_values('activity', activities) # Create 'activity' column\n",
    "        df = df.join(self.count_by_values('text_change', text_changes), on='id', how='left') \n",
    "        df = df.join(self.count_by_values('down_event', events), on='id', how='left') \n",
    "        df = df.join(self.count_by_values('up_event', events), on='id', how='left')\n",
    "        # print(df.collect().head())\n",
    "        return df\n",
    "\n",
    "    # Create the features \n",
    "    def create_input_words_feats(self):\n",
    "        # Filter no changes \n",
    "        df = self.logs.filter((~pl.col('text_change').str.contains('=>')) & (pl.col('text_change') != 'NoChange'))\n",
    "        # Aggregate the text changes by id\n",
    "        df = df.group_by('id').agg(pl.col('text_change').str.concat('').str.extract_all(r'q+'))\n",
    "        # creates only two columns ('id' and 'text_change') \n",
    "        df = df.with_columns(input_word_count=pl.col('text_change').list.lengths(),\n",
    "                             input_word_length_mean=pl.col('text_change').apply(lambda x: np.mean([len(i) for i in x] if len(x) > 0 else 0)),\n",
    "                             input_word_length_max=pl.col('text_change').apply(lambda x: np.max([len(i) for i in x] if len(x) > 0 else 0)),\n",
    "                             input_word_length_std=pl.col('text_change').apply(lambda x: np.std([len(i) for i in x] if len(x) > 0 else 0)),\n",
    "                             input_word_length_median=pl.col('text_change').apply(lambda x: np.median([len(i) for i in x] if len(x) > 0 else 0)),\n",
    "                             input_word_length_skew=pl.col('text_change').apply(lambda x: skew([len(i) for i in x] if len(x) > 0 else 0)))\n",
    "        df = df.drop('text_change') # Remove 'text_change' to avoid including duplicated `text_change` column\n",
    "        return df\n",
    "    \n",
    "    # Create the statistical numeric features (e.g. sum, median, mean min, 0.5_quantile)\n",
    "    def create_numeric_feats(self):\n",
    "        num_cols = ['down_time', 'up_time', 'action_time', 'cursor_position', 'word_count']\n",
    "        df = self.logs.group_by(\"id\").agg(pl.sum('action_time').suffix('_sum'),\n",
    "                                                pl.mean(num_cols).suffix('_mean'),\n",
    "                                                pl.std(num_cols).suffix('_std'),\n",
    "                                                pl.median(num_cols).suffix('_median'), pl.min(num_cols).suffix('_min'), pl.max(num_cols).suffix('_max'),\n",
    "                                                pl.quantile(num_cols, 0.5).suffix('_quantile'))\n",
    "        return df\n",
    "    \n",
    "    def create_categorical_feats(self):\n",
    "        df  = self.logs.group_by(\"id\").agg(\n",
    "                pl.n_unique(['activity', 'down_event', 'up_event', 'text_change']))\n",
    "        return df\n",
    "    \n",
    "    # Create the idle time features \n",
    "    def create_idle_time_feats(self):\n",
    "        df = self.logs.with_columns(pl.col('up_time').shift().over('id').alias('up_time_lagged'))\n",
    "        df = df.with_columns((abs(pl.col('down_time') - pl.col('up_time_lagged')) / 1000).fill_null(0).alias('time_diff'))\n",
    "        df = df.filter(pl.col('activity').is_in(['Input', 'Remove/Cut']))\n",
    "        df = df.group_by(\"id\").agg(inter_key_largest_lantency = pl.max('time_diff'),\n",
    "                                   inter_key_median_lantency = pl.median('time_diff'),\n",
    "                                   mean_pause_time = pl.mean('time_diff'),\n",
    "                                   std_pause_time = pl.std('time_diff'),\n",
    "                                   total_pause_time = pl.sum('time_diff'),\n",
    "                                   pauses_half_sec = pl.col('time_diff').filter((pl.col('time_diff') > 0.5) & (pl.col('time_diff') < 1)).count(),\n",
    "                                   pauses_1_sec = pl.col('time_diff').filter((pl.col('time_diff') > 1) & (pl.col('time_diff') < 1.5)).count(),\n",
    "                                   pauses_1_half_sec = pl.col('time_diff').filter((pl.col('time_diff') > 1.5) & (pl.col('time_diff') < 2)).count(),\n",
    "                                   pauses_2_sec = pl.col('time_diff').filter((pl.col('time_diff') > 2) & (pl.col('time_diff') < 3)).count(),\n",
    "                                   pauses_3_sec = pl.col('time_diff').filter(pl.col('time_diff') > 3).count(),)\n",
    "        return df\n",
    "    \n",
    "    # Create p-bursts features using up and down time and activity\n",
    "    def create_p_bursts_feats(self):\n",
    "        df = self.logs.with_columns(pl.col('up_time').shift().over('id').alias('up_time_lagged'))\n",
    "        df = df.with_columns((abs(pl.col('down_time') - pl.col('up_time_lagged')) / 1000).fill_null(0).alias('time_diff'))\n",
    "        df = df.filter(pl.col('activity').is_in(['Input', 'Remove/Cut']))\n",
    "        df = df.with_columns(pl.col('time_diff')<2)\n",
    "        df = df.with_columns(pl.when(pl.col(\"time_diff\") & pl.col(\"time_diff\").is_last()).then(pl.count()).over(pl.col(\"time_diff\").rle_id()).alias('P-bursts'))\n",
    "        df = df.drop_nulls()\n",
    "        df = df.group_by(\"id\").agg(pl.mean('P-bursts').suffix('_mean'),\n",
    "                                   pl.std('P-bursts').suffix('_std'),\n",
    "                                   pl.count('P-bursts').suffix('_count'),\n",
    "                                   pl.median('P-bursts').suffix('_median'),\n",
    "                                   pl.max('P-bursts').suffix('_max'),\n",
    "                                   pl.first('P-bursts').suffix('_first'),\n",
    "                                   pl.last('P-bursts').suffix('_last'))\n",
    "        return df\n",
    "    \n",
    "    # Create r-burst features using activity \n",
    "    def create_r_bursts_feats(self):\n",
    "        df = self.logs.filter(pl.col('activity').is_in(['Input', 'Remove/Cut']))\n",
    "        df = df.with_columns(pl.col('activity').is_in(['Remove/Cut']))\n",
    "        df = df.with_columns(pl.when(pl.col(\"activity\") & pl.col(\"activity\").is_last()).then(pl.count()).over(pl.col(\"activity\").rle_id()).alias('R-bursts'))\n",
    "        df = df.drop_nulls()\n",
    "        df = df.group_by(\"id\").agg(pl.mean('R-bursts').suffix('_mean'),\n",
    "                                   pl.std('R-bursts').suffix('_std'), \n",
    "                                   pl.median('R-bursts').suffix('_median'),\n",
    "                                   pl.max('R-bursts').suffix('_max'),\n",
    "                                   pl.first('R-bursts').suffix('_first'),\n",
    "                                   pl.last('R-bursts').suffix('_last'))\n",
    "        return df\n",
    "    \n",
    "    # Main function creates all 122 features\n",
    "    def create_feats(self):\n",
    "        feats = self.create_count_by_values_feats()  # 52 columns in total\n",
    "#         print(f\"< Count by values features > {len(feats.columns)}\")        \n",
    "        feats = feats.join(self.create_input_words_feats(), on='id', how='left')  # 58 columns\n",
    "#         print(f\"< Input words stats features > {len(feats.columns)}\")\n",
    "        feats = feats.join(self.create_numeric_feats(), on='id', how='left') # 89 columns\n",
    "#         print(f\"< Numerical features > {len(feats.columns)}\")\n",
    "        feats = feats.join(self.create_categorical_feats(), on='id', how='left') # 93 columns      \n",
    "#         print(f\"< Categorical features > {len(feats.columns)}\")\n",
    "        feats = feats.join(self.create_idle_time_feats(), on='id', how='left') # 103 columns\n",
    "#         print(f\"< Idle time features > {len(feats.columns)}\")\n",
    "        feats = feats.join(self.create_p_bursts_feats(), on='id', how='left') # 110 columns\n",
    "#         print(f\"< P-bursts features > {len(feats.columns)}\")\n",
    "        feats = feats.join(self.create_r_bursts_feats() , on='id', how='left') # 116 columns\n",
    "#         print(f\"< R-bursts features > {len(feats.columns)}\")        \n",
    "        return feats # 116 features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "545f75b8-53ed-4ebb-85de-aed3c0f4caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = FeatureExtractor(train_logs)\n",
    "train_feats = fe.create_feats() # Extract features from trainning logs (polars df)\n",
    "train_feats = train_feats.collect().to_pandas() # Convert polars df to pandas df\n",
    "train_feats.to_csv(\"train_feats_0.csv\")\n",
    "# print(train_feats.describe())\n",
    "train_logs = train_logs.collect().to_pandas()  # Convert polars df to pandas df\n",
    "del fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdee2d3e-69c9-43ac-8847-450e00a64251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1(x):\n",
    "    return x.quantile(0.25)\n",
    "def q3(x):\n",
    "    return x.quantile(0.75)\n",
    "\n",
    "class EssayConstructor():\n",
    "    def __init__(self, logs):\n",
    "        self.logs = logs\n",
    "        self.train_essays = self.get_train_essays(self.logs)\n",
    "        self.AGGREGATIONS = ['count', 'mean', 'min', 'max', 'first', 'last', q1, 'median', q3, 'sum']\n",
    "    \n",
    "    # Get the essay from train logs \n",
    "    def get_train_essays(self, logs):\n",
    "        def reconstruct_essay(currTextInput):\n",
    "            essayText = \"\"\n",
    "            for Input in currTextInput.values:\n",
    "                if Input[0] == 'Replace':\n",
    "                    replaceTxt = Input[2].split(' => ')\n",
    "                    essayText = essayText[:Input[1] - len(replaceTxt[1])] + replaceTxt[1] + essayText[Input[1] - len(replaceTxt[1]) + len(replaceTxt[0]):]\n",
    "                    continue\n",
    "                if Input[0] == 'Paste':\n",
    "                    essayText = essayText[:Input[1] - len(Input[2])] + Input[2] + essayText[Input[1] - len(Input[2]):]\n",
    "                    continue\n",
    "                if Input[0] == 'Remove/Cut':\n",
    "                    essayText = essayText[:Input[1]] + essayText[Input[1] + len(Input[2]):]\n",
    "                    continue\n",
    "                if \"M\" in Input[0]:\n",
    "                    croppedTxt = Input[0][10:]\n",
    "                    splitTxt = croppedTxt.split(' To ')\n",
    "                    valueArr = [item.split(', ') for item in splitTxt]\n",
    "                    moveData = (int(valueArr[0][0][1:]), int(valueArr[0][1][:-1]), int(valueArr[1][0][1:]), int(valueArr[1][1][:-1]))\n",
    "                    if moveData[0] != moveData[2]:\n",
    "                        if moveData[0] < moveData[2]:\n",
    "                            essayText = essayText[:moveData[0]] + essayText[moveData[1]:moveData[3]] + essayText[moveData[0]:moveData[1]] + essayText[moveData[3]:]\n",
    "                        else:\n",
    "                            essayText = essayText[:moveData[2]] + essayText[moveData[0]:moveData[1]] + essayText[moveData[2]:moveData[0]] + essayText[moveData[1]:]\n",
    "                    continue\n",
    "                essayText = essayText[:Input[1] - len(Input[2])] + Input[2] + essayText[Input[1] - len(Input[2]):]\n",
    "            return essayText\n",
    "        \n",
    "        # Filter logs \n",
    "        df = logs[logs.activity != 'Nonproduction']\n",
    "        group_df = df.groupby('id').apply(lambda x: reconstruct_essay(x[['activity', 'cursor_position', 'text_change']]))\n",
    "        essay_df = pd.DataFrame({'id': df['id'].unique().tolist()})\n",
    "        essay_df = essay_df.merge(group_df.rename('essay'), on='id')\n",
    "        return essay_df\n",
    "\n",
    "    # Create word level features from train essay\n",
    "    def create_word_feats(self):\n",
    "        df = self.train_essays.copy()\n",
    "        df['word'] = df['essay'].apply(lambda x: re.split(' |\\\\n|\\\\.|\\\\?|\\\\!',x))\n",
    "        df = df.explode('word')\n",
    "        df['word_len'] = df['word'].apply(lambda x: len(x))\n",
    "        df = df[df['word_len'] != 0] # Remove all the no-word record\n",
    "        # Aggregate word level features\n",
    "        word_agg_df = df[['id','word_len']].groupby(['id']).agg(self.AGGREGATIONS)\n",
    "        word_agg_df.columns = ['_'.join(x) for x in word_agg_df.columns]\n",
    "        word_agg_df['id'] = word_agg_df.index\n",
    "        word_agg_df = word_agg_df.reset_index(drop=True)\n",
    "        return word_agg_df\n",
    "    # Create sentence level features\n",
    "    def create_sentence_feats(self):\n",
    "        df = self.train_essays.copy()\n",
    "        df['sent'] = df['essay'].apply(lambda x: re.split('\\\\.|\\\\?|\\\\!',x))\n",
    "        df = df.explode('sent')\n",
    "        df['sent'] = df['sent'].apply(lambda x: x.replace('\\n','').strip())\n",
    "        # Number of characters in sentences\n",
    "        df['sent_len'] = df['sent'].apply(lambda x: len(x))\n",
    "        # Number of words in sentences\n",
    "        df['sent_word_count'] = df['sent'].apply(lambda x: len(x.split(' ')))\n",
    "        df = df[df.sent_len!=0].reset_index(drop=True)\n",
    "        # Aggregate sentence level features\n",
    "        sent_agg_df = pd.concat([df[['id','sent_len']].groupby(['id']).agg(self.AGGREGATIONS), \n",
    "                                 df[['id','sent_word_count']].groupby(['id']).agg(self.AGGREGATIONS)], axis=1)\n",
    "        sent_agg_df.columns = ['_'.join(x) for x in sent_agg_df.columns]\n",
    "        sent_agg_df['id'] = sent_agg_df.index\n",
    "        sent_agg_df = sent_agg_df.reset_index(drop=True)\n",
    "        sent_agg_df.drop(columns=[\"sent_word_count_count\"], inplace=True)\n",
    "        sent_agg_df = sent_agg_df.rename(columns={\"sent_len_count\":\"sent_count\"})\n",
    "        return sent_agg_df\n",
    "    # Create paragraph level features\n",
    "    def create_paragraph_feats(self):\n",
    "        df = self.train_essays.copy()\n",
    "        df['paragraph'] = df['essay'].apply(lambda x: x.split('\\n'))\n",
    "        df = df.explode('paragraph')\n",
    "        # Number of characters in paragraphs\n",
    "        df['paragraph_len'] = df['paragraph'].apply(lambda x: len(x)) \n",
    "        # Number of words in paragraphs\n",
    "        df['paragraph_word_count'] = df['paragraph'].apply(lambda x: len(x.split(' ')))\n",
    "        df = df[df.paragraph_len!=0].reset_index(drop=True)\n",
    "        # Aggregate paragraph level features\n",
    "        paragraph_agg_df = pd.concat([df[['id','paragraph_len']].groupby(['id']).agg(self.AGGREGATIONS), \n",
    "                                      df[['id','paragraph_word_count']].groupby(['id']).agg(self.AGGREGATIONS)], axis=1) \n",
    "        paragraph_agg_df.columns = ['_'.join(x) for x in paragraph_agg_df.columns]\n",
    "        paragraph_agg_df['id'] = paragraph_agg_df.index\n",
    "        paragraph_agg_df = paragraph_agg_df.reset_index(drop=True)\n",
    "        paragraph_agg_df.drop(columns=[\"paragraph_word_count_count\"], inplace=True)\n",
    "        paragraph_agg_df = paragraph_agg_df.rename(columns={\"paragraph_len_count\":\"paragraph_count\"})\n",
    "        return paragraph_agg_df\n",
    "\n",
    "    \n",
    "    # Create product to keys features\n",
    "    def create_product_to_keys_feats(self):\n",
    "        essays = self.train_essays.copy()\n",
    "        logs = self.logs.copy()\n",
    "        essays['product_len'] = essays['essay'].str.len()\n",
    "        tmp_df = logs[logs['activity'].isin(['Input', 'Remove/Cut'])].groupby(['id']).agg({'activity': 'count'}).reset_index().rename(columns={'activity': 'keys_pressed'})\n",
    "        essays = essays.merge(tmp_df, on='id', how='left')\n",
    "        essays['product_to_keys'] = essays['product_len'] / essays['keys_pressed']\n",
    "        return essays[['id', 'product_to_keys']]\n",
    "\n",
    "    # Create key pressed features\n",
    "    def create_keys_pressed_feats(self):\n",
    "        logs = self.logs.copy()\n",
    "        temp_df = logs[logs['activity'].isin(['Input', 'Remove/Cut'])].groupby(['id']).agg(keys_pressed=('event_id', 'count')).reset_index()\n",
    "        temp_df_2 = logs.groupby(['id']).agg(min_down_time=('down_time', 'min'), max_up_time=('up_time', 'max')).reset_index()\n",
    "        temp_df = temp_df.merge(temp_df_2, on='id', how='left')\n",
    "        temp_df['keys_per_second'] = temp_df['keys_pressed'] / ((temp_df['max_up_time'] - temp_df['min_down_time']) / 1000)\n",
    "        return temp_df[['id', 'keys_per_second']]\n",
    "    \n",
    "    def create_feats(self, feats):\n",
    "        feats = feats.merge(self.create_word_feats(), on='id', how='left') # 126 columns in total\n",
    "#         print(f\"{len(feats.columns)}\")\n",
    "        feats = feats.merge(self.create_sentence_feats(), on='id', how='left') # 145 columns\n",
    "#         print(f\"{len(feats.columns)}\")\n",
    "        feats = feats.merge(self.create_paragraph_feats(), on='id', how='left') # 164 columns\n",
    "#         print(f\"{len(feats.columns)}\")\n",
    "        feats = feats.merge(self.create_keys_pressed_feats(), on='id', how='left') # 166 columns\n",
    "#         print(f\"{len(feats.columns)}\")\n",
    "        feats = feats.merge(self.create_product_to_keys_feats(), on='id', how='left') # 165 columns\n",
    "#         print(f\"{len(feats.columns)}\")\n",
    "        return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f93108d-3c13-4315-b630-d27a8841cfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Essay Reconstruction >\n"
     ]
    }
   ],
   "source": [
    "print('< Essay Reconstruction >')\n",
    "ec = EssayConstructor(train_logs)\n",
    "train_feats = ec.create_feats(train_feats)\n",
    "# Writing to csg\n",
    "train_feats.to_csv(\"train_feats.csv\")\n",
    "del ec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e999ef57-e141-453f-9b5b-888ed7e6b261",
   "metadata": {},
   "source": [
    "## Create train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "609bed46-6089-4f12-9286-4435ded0c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv(\"data/raw/train_scores.csv\")\n",
    "train_df = train_feats.merge(target, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb49d4e8-e842-4ecc-910c-34b102dc288e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>activity_0_cnt</th>\n",
       "      <th>activity_1_cnt</th>\n",
       "      <th>activity_2_cnt</th>\n",
       "      <th>activity_3_cnt</th>\n",
       "      <th>activity_4_cnt</th>\n",
       "      <th>text_change_0_cnt</th>\n",
       "      <th>text_change_1_cnt</th>\n",
       "      <th>text_change_2_cnt</th>\n",
       "      <th>text_change_3_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>paragraph_word_count_max</th>\n",
       "      <th>paragraph_word_count_first</th>\n",
       "      <th>paragraph_word_count_last</th>\n",
       "      <th>paragraph_word_count_q1</th>\n",
       "      <th>paragraph_word_count_median</th>\n",
       "      <th>paragraph_word_count_q3</th>\n",
       "      <th>paragraph_word_count_sum</th>\n",
       "      <th>keys_per_second</th>\n",
       "      <th>product_to_keys</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001519c8</td>\n",
       "      <td>2010</td>\n",
       "      <td>417</td>\n",
       "      <td>120</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1940</td>\n",
       "      <td>436</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>71</td>\n",
       "      <td>86</td>\n",
       "      <td>78.50</td>\n",
       "      <td>86.0</td>\n",
       "      <td>99.00</td>\n",
       "      <td>269</td>\n",
       "      <td>1.350251</td>\n",
       "      <td>0.629584</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022f953</td>\n",
       "      <td>1938</td>\n",
       "      <td>260</td>\n",
       "      <td>254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1698</td>\n",
       "      <td>432</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>53</td>\n",
       "      <td>60</td>\n",
       "      <td>47.75</td>\n",
       "      <td>56.5</td>\n",
       "      <td>62.25</td>\n",
       "      <td>355</td>\n",
       "      <td>1.250038</td>\n",
       "      <td>0.762056</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0042269b</td>\n",
       "      <td>3515</td>\n",
       "      <td>439</td>\n",
       "      <td>175</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3257</td>\n",
       "      <td>615</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>55.50</td>\n",
       "      <td>73.5</td>\n",
       "      <td>78.75</td>\n",
       "      <td>410</td>\n",
       "      <td>2.237402</td>\n",
       "      <td>0.654274</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0059420b</td>\n",
       "      <td>1304</td>\n",
       "      <td>151</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1146</td>\n",
       "      <td>281</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>62</td>\n",
       "      <td>65</td>\n",
       "      <td>63.50</td>\n",
       "      <td>65.0</td>\n",
       "      <td>73.00</td>\n",
       "      <td>208</td>\n",
       "      <td>1.067440</td>\n",
       "      <td>0.793127</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0075873a</td>\n",
       "      <td>1942</td>\n",
       "      <td>517</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1964</td>\n",
       "      <td>397</td>\n",
       "      <td>32</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>114</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>26.00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>61.00</td>\n",
       "      <td>256</td>\n",
       "      <td>1.552397</td>\n",
       "      <td>0.579504</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  activity_0_cnt  activity_1_cnt  activity_2_cnt  activity_3_cnt  \\\n",
       "0  001519c8            2010             417             120               7   \n",
       "1  0022f953            1938             260             254               1   \n",
       "2  0042269b            3515             439             175               7   \n",
       "3  0059420b            1304             151              99               1   \n",
       "4  0075873a            1942             517              72               0   \n",
       "\n",
       "   activity_4_cnt  text_change_0_cnt  text_change_1_cnt  text_change_2_cnt  \\\n",
       "0               0               1940                436                 28   \n",
       "1               1               1698                432                 18   \n",
       "2               0               3257                615                 23   \n",
       "3               1               1146                281                 13   \n",
       "4               0               1964                397                 32   \n",
       "\n",
       "   text_change_3_cnt  ...  paragraph_word_count_max  \\\n",
       "0                 14  ...                       112   \n",
       "1                 24  ...                        96   \n",
       "2                 26  ...                        88   \n",
       "3                  3  ...                        81   \n",
       "4                 25  ...                       114   \n",
       "\n",
       "   paragraph_word_count_first  paragraph_word_count_last  \\\n",
       "0                          71                         86   \n",
       "1                          53                         60   \n",
       "2                          79                         45   \n",
       "3                          62                         65   \n",
       "4                          61                          3   \n",
       "\n",
       "   paragraph_word_count_q1  paragraph_word_count_median  \\\n",
       "0                    78.50                         86.0   \n",
       "1                    47.75                         56.5   \n",
       "2                    55.50                         73.5   \n",
       "3                    63.50                         65.0   \n",
       "4                    26.00                         52.0   \n",
       "\n",
       "   paragraph_word_count_q3  paragraph_word_count_sum  keys_per_second  \\\n",
       "0                    99.00                       269         1.350251   \n",
       "1                    62.25                       355         1.250038   \n",
       "2                    78.75                       410         2.237402   \n",
       "3                    73.00                       208         1.067440   \n",
       "4                    61.00                       256         1.552397   \n",
       "\n",
       "   product_to_keys  score  \n",
       "0         0.629584    3.5  \n",
       "1         0.762056    3.5  \n",
       "2         0.654274    6.0  \n",
       "3         0.793127    2.0  \n",
       "4         0.579504    4.0  \n",
       "\n",
       "[5 rows x 167 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1032297b-4a9e-4d4b-8aef-0871a1833745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2471 entries, 0 to 2470\n",
      "Columns: 167 entries, id to score\n",
      "dtypes: float64(61), int64(40), object(1), uint32(65)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42edfac3-87db-44db-ac39-9dadbf93595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the unique identifier and the target\n",
    "X_train = train_df.drop([\"id\",\"score\"], axis=1)\n",
    "y_train = train_df['score'].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:573]",
   "language": "python",
   "name": "conda-env-573-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
